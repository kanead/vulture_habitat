swazi_data$New_time<-parse_date_time(x=swazi_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
swazi_data <- select(swazi_data, New_time,long,lat,id,species,study)
swazi_data <- rename(swazi_data, time = New_time)
swazi_data
#' estimate vmax for threshold speed
#' names(swazi_data)[names(swazi_data) == 'time'] <- 'DateTime'
#' speed.est.data <- swazi_data %>% filter(id == "ID2") %>%  select(id,DateTime,lat,long)
#' speed.est.data$qi = 5
#' est.vmax(sdata = data.frame(speed.est.data))
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(swazi_data)[names(swazi_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(swazi_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
swazi_data <- SDLfilterData
names(swazi_data)[names(swazi_data) == 'DateTime'] <- 'time'
trk <-
mk_track(
swazi_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326"))  %>%
transform_coords(
sp::CRS( #' we can transform the CRS of the data to an equal area projection
#' https://epsg.io/102022
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
trk$x_
loc <-
move(
x = trk$x_,
y = trk$y_,
time = trk$t_,
proj = CRS("+proj=utm"),
data = trk,
animal = trk$id
)
#' Dynamic Brownian Bridge Models Using move Package
#' load the move package
require(move)
loc <-
move(
x = trk$x_,
y = trk$y_,
time = trk$t_,
proj = CRS("+proj=utm"),
data = trk,
animal = trk$id
)
track <- data.frame(trk)
#' create a move object
loc <-
move(
x = track$x_,
y = track$y_,
time = track$t_,
proj = CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"),
data = track,
animal = track$id
)
track
trk <-
mk_track(
swazi_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)  %>%
transform_coords(
sp::CRS(
#' we can transform the CRS of the data to an equal area projection
#' https://epsg.io/102022
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
trk
?sort
track <- arrange(track, id)
track
#' create a move object
loc <-
move(
x = track$x_,
y = track$y_,
time = track$t_,
proj = CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"),
data = track,
animal = track$id
)
50*2
?brownian.bridge.dyn
#' Now create a dBBMM object
dbbmm <-
brownian.bridge.dyn(
object = loc,
location.error = 18,
window.size = 360,
margin = 7,
raster = 100
)
dbbmm <-
brownian.bridge.dyn(
object = loc,
location.error = 18,
window.size = 101,
margin = 7,
raster = 100
)
writeRaster(dbbmm, filename='brownian_bridges/swazi_dbbm.tif', overwrite=TRUE)
plot(dbbmm)
contour(dbbmm, add=T, levels=c(.5,.95))
str(dbbmm)
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
mydata <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
#' filter the data to remove obvious outliers
mydata <- filter(mydata, lat < 20 & lat > -40 & long > 10)
head(mydata)
tail(mydata)
str(mydata)
levels(as.factor(mydata$study))
# Corinne Kendall's Tanzania Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# ck_tanz
# select ck_tanz data which is Corinne's data from everything
ck_tanz_data <- filter(mydata, study == "ck_tanz")
ck_tanz_data
#' Check for duplicated observations (ones with same lat, long, time,
#'  and individual identifier).
ind2 <- ck_tanz_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
ck_tanz_data$dups <- ind2
ck_tanz_data <- filter(ck_tanz_data, dups == "FALSE")
ck_tanz_data
# set the time column
levels(factor(ck_tanz_data$id))
# can look at an individual level with
(filter(ck_tanz_data, id == "#109018542"))
#' all of the data is in the format of day-month-year
#' time zone is UTC by default
#' raw data is 2 hours off the real time
#' CK said the recorder started at 6am with hourly points
#' including a relocation at midnight
ck_tanz_data$New_time <-
parse_date_time(x = ck_tanz_data$time, c("%d/%m/%Y %H:%M"), tz = "africa/dar_es_salaam") + hours(2)
# keep only the new time data
ck_tanz_data <-
select(ck_tanz_data, New_time, long, lat, id, species, study)
ck_tanz_data <- rename(ck_tanz_data, time = New_time)
ck_tanz_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(ck_tanz_data)[names(ck_tanz_data) == 'time'] <- 'DateTime'
SDLfilterData <-
ddfilter.speed(data.frame(ck_tanz_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
ck_tanz_data <- SDLfilterData
names(ck_tanz_data)[names(ck_tanz_data) == 'DateTime'] <- 'time'
ck_tanz_data <- ck_tanz_data  %>%
filter(!((id == "#199122325" & lat < -10)))
#' load the move package
require(move)
#' transform the CRS
#' try the amt package
trk <-
mk_track(
ck_tanz_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)  %>%
transform_coords(
sp::CRS(
#' we can transform the CRS of the data to an equal area projection
#' https://epsg.io/102022
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
track <- data.frame(trk)
track <- arrange(track, id)
#' create a move object
loc <-
move(
x = track$x_,
y = track$y_,
time = track$t_,
proj = CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"),
data = track,
animal = track$id
)
#' Now create a dBBMM object
dbbmm <-
brownian.bridge.dyn(
object = loc,
location.error = 18,
window.size = 31,
margin = 15,
raster = 100
)
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
mydata <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
#' filter the data to remove obvious outliers
mydata <- filter(mydata, lat < 20 & lat > -40 & long > 10)
head(mydata)
tail(mydata)
str(mydata)
levels(as.factor(mydata$study))
# Mendelsohn Namibia Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# mend
# select mend data which is data from everything
mend_data <- filter(mydata, study == "mend")
mend_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-mend_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
mend_data$dups <- ind2
mend_data <- filter(mend_data,dups=="FALSE")
mend_data
# set the time column
levels(factor(mend_data$id))
# can look at an individual level with
(filter(mend_data,id=="WBV1__44782"))
# all of the data is in the format of day-month-year
mend_data$New_time<-parse_date_time(x=mend_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
mend_data <- select(mend_data, New_time,long,lat,id,species,study)
mend_data <- rename(mend_data, time = New_time)
mend_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(mend_data)[names(mend_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(mend_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
mend_data <- SDLfilterData
names(mend_data)[names(mend_data) == 'DateTime'] <- 'time'
#' Dynamic Brownian Bridge Models Using move Package
#' load the move package
require(move)
#' transform the CRS
#' try the amt package
trk <-
mk_track(
mend_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)  %>%
transform_coords(
sp::CRS(
#' we can transform the CRS of the data to an equal area projection
#' https://epsg.io/102022
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
track <- data.frame(trk)
track <- arrange(track, id)
#' create a move object
loc <-
move(
x = track$x_,
y = track$y_,
time = track$t_,
proj = CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"),
data = track,
animal = track$id
)
#' Now create a dBBMM object
dbbmm <-
brownian.bridge.dyn(
object = loc,
location.error = 18,
window.size = 31,
margin = 15,
raster = 100
)
head(track)
#' select one individual because the vector size is too big
track <- filter(track, id == "CV1__44780")
#' create a move object
loc <-
move(
x = track$x_,
y = track$y_,
time = track$t_,
proj = CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"),
data = track,
animal = track$id
)
#' Now create a dBBMM object
dbbmm <-
brownian.bridge.dyn(
object = loc,
location.error = 18,
window.size = 31,
margin = 15,
raster = 100
)
trk <-
mk_track(
mend_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)  %>%
transform_coords(
sp::CRS(
#' we can transform the CRS of the data to an equal area projection
#' https://epsg.io/102022
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
track <- data.frame(trk)
track <- arrange(track, id)
tail(track)
track <- data.frame(trk)
track <- arrange(track, id)
#' select one individual because the vector size is too big
track <- filter(track, id == "WBV1__44782")
#' create a move object
loc <-
move(
x = track$x_,
y = track$y_,
time = track$t_,
proj = CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"),
data = track,
animal = track$id
)
#' Now create a dBBMM object
dbbmm <-
brownian.bridge.dyn(
object = loc,
location.error = 18,
window.size = 31,
margin = 15,
raster = 100
)
writeRaster(dbbmm, filename='brownian_bridges/mend_data_WBV1__44782.tif', overwrite=TRUE)
plot(dbbmm)
contour(dbbmm, add=T, levels=c(.5,.95))
raster2contour(dbbmm)
trk_map <-
mk_track(
mend_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)
trk_map <- filter(trk_map, id == "WBV1__44782")
#' plot all of the data on the one graph
library(ggmap)
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id)
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id, xlab = "longitude", ylab = "latitude")
?qmplot
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id,
xlab = "longitude",
ylab = "latitude")
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id,
padding = 0.1,
xlab = "longitude",
ylab = "latitude")
#' plot all of the data on the one graph
library(ggmap)
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id,
padding = 3,
xlab = "longitude",
ylab = "latitude")
#' plot all of the data on the one graph
library(ggmap)
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id,
legend = "none",
xlab = "longitude",
ylab = "latitude")
devtools::install_github("dkahle/ggmap" ).
devtools::install_github("dkahle/ggmap" )
install.packages("ggmap")
install.packages("ggmap")
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id,
legend = "none",
xlab = "longitude",
ylab = "latitude")
qmplot(x_,
y_,
data = trk_map
)
qmplot(x_,
y_,
data = trk_map
,
xlab = "longitude",
ylab = "latitude")
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id,
legend = "none",
xlab = "longitude",
ylab = "latitude")
#' get the area of the bb
bb.95 <- getverticeshr(dbbmm, percent = 95)
library(adehabitatHR)
#' get the area of the bb
bb.95 <- getverticeshr(dbbmm, percent = 95)
class(dbbmm)
show(dbbmm)
bbmm.contour = data.frame(x = dbbmm$x, y = dbbmm$y, probability = dbbmm$probability)
show(dbbmm)
(52 / 52 * 225)
(52 / 104 * 225)
(52 / 156 * 225)
(14 / 66 * 225)
show(dbbmm)
class(dbbmm)
raster2contour(dbbmm)
?raster2contour
