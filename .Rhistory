mcps <- trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
mcps$area <- mcps$area / 1000000
mcp_95 <- mcps %>% arrange(id)
#' Same for KDE
kde <- trk %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
select(id, kdearea) %>% unnest()
kde$kdearea <-  kde$kdearea / 1000000
kde_95 <- kde %>% arrange(id)
#' combine the summary stats
data_summary$duration <- duration
data_summary$min_time <- min_time$time
data_summary$max_time <- max_time$time
data_summary$kde <- kde_95$kdearea
data_summary$mcps <- mcp_95$area
data_summary$species <- min_time$species
data_summary$study <- "inter"
data_summary
write.csv(data_summary, file="track_resolution_summary/inter_data_summary.csv", row.names = FALSE)
trk_map <-
mk_track(
inter_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)
#' plot all of the data on the one graph
library(ggmap)
qmplot(x_,
y_,
data = trk_map,
maptype = "toner-lite",
colour = id)
#  color = I("red"))
#' plot each track on a separate panel using facet
levels(mydata$study)
levels(as.factor(mydata$study))
# Kerri's Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# kerri
# select kerri data which is kerri's data from the full data set
kerri_data <- filter(mydata, study == "kerri")
kerri_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-kerri_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
kerri_data$dups <- ind2
kerri_data <- filter(kerri_data,dups=="FALSE")
kerri_data
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="22959306")
# all of the data is in the format of day-month-year
kerri_data$New_time<-parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M:%S"))
# all of the data is in the format of day-month-year
kerri_data$New_time<-parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M"))
# all of the data is in the format of day-month-year
kerri_data$New_time<-kerri_data %>% filter(gmt == "GMT") %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M"))
kerri_data$New_time<-kerri_data %>% filter(gmt == "GMT")
# Kerri's Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# kerri
# select kerri data which is kerri's data from the full data set
kerri_data <- filter(mydata, study == "kerri")
kerri_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-kerri_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
kerri_data$dups <- ind2
kerri_data <- filter(kerri_data,dups=="FALSE")
kerri_data
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="22959306")
kerri_data %>% filter(gmt == "GMT")
# all of the data is in the format of day-month-year
kerri_data$New_time<-
kerri_data %>% filter(gmt == "GMT") %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M"))
kerri_data %>% filter(gmt == "GMT") %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M"))
# can look at an individual level with
filter(kerri_data,id=="22959306")
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="27230695")
# can look at an individual level with
filter(kerri_data,id=="27233665")
# can look at an individual level with
filter(kerri_data,id=="33640")
# can look at an individual level with
filter(kerri_data,id=="33798")
# can look at an individual level with
filter(kerri_data,id=="5008")
# can look at an individual level with
filter(kerri_data,id=="AG313")
# can look at an individual level with
filter(kerri_data,id=="AG314")
# can look at an individual level with
filter(kerri_data,id=="AG329")
# can look at an individual level with
filter(kerri_data,id=="AG330")
# can look at an individual level with
filter(kerri_data,id=="AG331")
# can look at an individual level with
filter(kerri_data,id=="AG332")
# can look at an individual level with
filter(kerri_data,id=="AG349")
# can look at an individual level with
filter(kerri_data,id=="AG350")
# can look at an individual level with
filter(kerri_data,id=="AG351")
# can look at an individual level with
filter(kerri_data,id=="AG352")
# can look at an individual level with
filter(kerri_data,id=="AG353")
# can look at an individual level with
filter(kerri_data,id=="AG382")
# can look at an individual level with
filter(kerri_data,id=="AM220")
# can look at an individual level with
filter(kerri_data,id=="AM222")
# can look at an individual level with
filter(kerri_data,id=="AM226")
# can look at an individual level with
filter(kerri_data,id=="AM227")
# can look at an individual level with
filter(kerri_data,id=="AM233")
# can look at an individual level with
filter(kerri_data,id=="AM234")
# can look at an individual level with
filter(kerri_data,id=="AM235")
# can look at an individual level with
filter(kerri_data,id=="AM240")
# can look at an individual level with
filter(kerri_data,id=="AM264")
# can look at an individual level with
filter(kerri_data,id=="AM267")
# can look at an individual level with
filter(kerri_data,id=="AM272")
# can look at an individual level with
filter(kerri_data,id=="AM295")
# can look at an individual level with
filter(kerri_data,id=="AM86")
# can look at an individual level with
filter(kerri_data,id=="AM87")
# can look at an individual level with
filter(kerri_data,id=="AM88")
# can look at an individual level with
filter(kerri_data,id=="AM89")
# can look at an individual level with
filter(kerri_data,id=="Ingelheim")
# can look at an individual level with
filter(kerri_data,id=="LFV_009")
# can look at an individual level with
filter(kerri_data,id=="X009")
# Masai Mara Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# mara
# select mara data which is Masai Mara data from everything
masai_data <- filter(mydata, study == "masai")
masai_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-masai_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
masai_data$dups <- ind2
masai_data <- filter(masai_data,dups=="FALSE")
masai_data
# set the time column
levels(factor(masai_data$id))
# can look at an individual level with
(filter(masai_data,id=="171605"))
# all of the data is in the format of day-month-year
masai_data$New_time<-parse_date_time(x=masai_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
masai_data <- select(masai_data, New_time,long,lat,id,species,study)
masai_data <- rename(masai_data, time = New_time)
masai_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
library(SDLfilter)
names(masai_data)[names(masai_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(masai_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
masai_data <- SDLfilterData
names(masai_data)[names(masai_data) == 'DateTime'] <- 'time'
# check the minimum time and the maximum time
min_time <- masai_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- masai_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' determine the length of time each bird was tracked for
duration <- difftime(max_time$time, min_time$time, units = "days"); duration
# try the amt package
trk <-
mk_track(
masai_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
) %>%
transform_coords(
sp::CRS(
#' we can transform the CRS of the data to an equal area projection
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
#' summarise the sampling rate
data_summary <- trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest %>% arrange(id) ; data_summary
#' Calculate home range size for data that is not regularised
mcps <- trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
mcps$area <- mcps$area / 1000000
mcp_95 <- mcps %>% arrange(id)
#' Same for KDE
kde <- trk %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
select(id, kdearea) %>% unnest()
kde_95 <- kde %>% arrange(id)
kde$kdearea <-  kde$kdearea / 1000000
#' combine the summary stats
data_summary$duration <- duration
data_summary$min_time <- min_time$time
data_summary$max_time <- max_time$time
data_summary$kde <- kde_95$kdearea
data_summary$mcps <- mcp_95$area
data_summary$species <- min_time$species
data_summary$study <- "masai"
data_summary
write.csv(data_summary, file="track_resolution_summary/masai_data_summary.csv", row.names = FALSE)
# Kerri's Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# kerri
# select kerri data which is kerri's data from the full data set
kerri_data <- filter(mydata, study == "kerri")
kerri_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-kerri_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
kerri_data$dups <- ind2
kerri_data <- filter(kerri_data,dups=="FALSE")
kerri_data
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="X009")
?parse_date_time
kerri_data %>% filter(gmt == "GMT") %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M", "%Y/%m/%d %H:%M",
"%d/%m/%Y %H:%M:%S", "%Y/%m/%d %H:%M:%S"))
kerri_data %>% filter(gmt == "GMT" & id == c("22959306", "27230695", "27233665", "33640", "33798")) %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M", "%Y/%m/%d %H:%M",
"%d/%m/%Y %H:%M:%S", "%Y/%m/%d %H:%M:%S"))
# can look at an individual level with
filter(kerri_data,id=="22959306")
# can look at an individual level with
filter(kerri_data,id=="22959306")
# can look at an individual level with
filter(kerri_data,id=="27230695")
# can look at an individual level with
filter(kerri_data,id=="27233665")
# all of the data is in the format of day-month-year
kerri_data$New_time<-
kerri_data %>% filter(gmt == "GMT" & id == c("22959306", "27230695", "27233665")) %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M"))
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
mydata <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
#' filter the data to remove obvious outliers
mydata <- filter(mydata, lat < 20 & lat > -40 & long > 10)
head(mydata)
tail(mydata)
str(mydata)
levels(as.factor(mydata$study))
# Kerri's Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# kerri
# select kerri data which is kerri's data from the full data set
kerri_data <- filter(mydata, study == "kerri")
kerri_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-kerri_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
kerri_data$dups <- ind2
kerri_data <- filter(kerri_data,dups=="FALSE")
kerri_data
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="27233665")
# all of the data is in the format of day-month-year
kerri_data$New_time<-
kerri_data %>% filter(id == c("22959306", "27230695", "27233665")) %>% parse_date_time(x=kerri_data$time,c("%d/%m/%Y %H:%M"))
# all of the data is in the format of day-month-year
kerri_data$New_time<-
kerri_data %>% filter(id == c("22959306", "27230695", "27233665")) %>% parse_date_time(time,c("%d/%m/%Y %H:%M"))
# all of the data is in the format of day-month-year
kerri_data$New_time<-
test <- kerri_data %>% filter(id == c("22959306", "27230695", "27233665"))
# all of the data is in the format of day-month-year
kerri_data$New_time<-
target <- c("22959306", "27230695", "27233665")
test<-  kerri_data %>% filter(id %in% target)
test
# all of the data is in the format of day-month-year
kerri_data$New_time<-
target <- c("22959306", "27230695", "27233665")
target <- c("22959306", "27230695", "27233665")
target
test <- kerri_data %>% filter(id %in% target)
test
tail(test)
levels(test$id)
levels(as.factor(test$id))
test$New_time<-parse_date_time(x=test$time,c("%d/%m/%Y %H:%M"))
test
target1 <- c("22959306", "27230695", "27233665")
test1 <- kerri_data %>% filter(id %in% target)
test1$New_time<-parse_date_time(x=test1$time,c("%d/%m/%Y %H:%M"))
target2 <- c("5008", "AG313", "AG314", "AG329", "AG330", "AG331", "AG332", "AG349", "AG350", "AG351", "AG352",
"AG353", "AG356", "AG382", "AM220", "AM222", "AM226", "AM227", "AM233", "AM234", "AM235", "AM240",
"AM264", "AM267", "AM272", "AM295", "AM86", "AM87", "AM88", "AM89")
target2 <- c("5008", "AG313", "AG314", "AG329", "AG330", "AG331", "AG332", "AG349", "AG350", "AG351", "AG352",
"AG353", "AG356", "AG382", "AM220", "AM222", "AM226", "AM227", "AM233", "AM234", "AM235", "AM240",
"AM264", "AM267", "AM272", "AM295", "AM86", "AM87", "AM88", "AM89")
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M"))
which(is.na(test2$New_time))
test2[,15106]
test2[15106,]
test2[16973,]
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S"))
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S", tz = "GMT") - hours(2)))
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S", tz = "GMT") - hours(2))
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S", tz = "Africa/Johannesburg"))
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S", tz = "africa/johannesburg"))
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M", "%d/%m/%Y %H:%M:%S", tz = "Africa/Johannesburg"))
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M",  tz = "Africa/Johannesburg"))
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M"), tz = "africa/johannesburg")
which(is.na(test2$New_time))
test3 %>% filter(which(is.na(test2$New_time)))
test3 <- test2 %>% filter(which(is.na(test2$New_time)))
test3 <- test2 %>% filter(test2$New_time == "NA")
test2$New_time
#' find out which dates failed to parse
which(is.na(test2$New_time))
test2[16973,]
test3 <-filter(test2,is.na(New_time))
test3
tail(test3)
levels(as.factor(test3$id))
levels(as.factor(test2$id))
filter(test2, id == "AM222")
# Kerri's Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# kerri
# select kerri data which is kerri's data from the full data set
kerri_data <- filter(mydata, study == "kerri")
kerri_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-kerri_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
kerri_data$dups <- ind2
kerri_data <- filter(kerri_data,dups=="FALSE")
kerri_data
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="27233665")
#' some data are GMT some are GMT + 2, some are unknown
#' GMT+2
#' 5008, AG313, AG314, AG329, AG330, AG331, AG332, AG349
#' AG350, AG351, AG352, AG353, AG356, AG382, AM220, AM222, AM226, AM227, AM233, AM234, AM235, AM240, AM264
#' AM267, AM272, AM295, AM86, AM87, AM88, AM89
#' AM22 has seconds listed for some time stamps so do AM227, AM234, AM235, AM240, AM264, AM267, AM272
#' GMT
#' Ingelheim, 22959306, 27230695, 27233665, 33640, 33798
#' Unknown
#' LFV_009, X009
#'
#' Some data have time arranged from most recent
#' Ingelheim
# all of the data is in the format of day-month-year
kerri_data$New_time<-
target1 <- c("22959306", "27230695", "27233665")
test1 <- kerri_data %>% filter(id %in% target1)
test1$New_time<-parse_date_time(x=test1$time,c("%d/%m/%Y %H:%M"))
target2 <- c("5008", "AG313", "AG314", "AG329", "AG330", "AG331", "AG332", "AG349", "AG350", "AG351", "AG352",
"AG353", "AG356", "AG382", "AM220", "AM222", "AM226", "AM227", "AM233", "AM234", "AM235", "AM240",
"AM264", "AM267", "AM272", "AM295", "AM86", "AM87", "AM88", "AM89")
# Kerri's Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# kerri
# select kerri data which is kerri's data from the full data set
kerri_data <- filter(mydata, study == "kerri")
kerri_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-kerri_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
kerri_data$dups <- ind2
kerri_data <- filter(kerri_data,dups=="FALSE")
kerri_data
# set the time column
levels(factor(kerri_data$id))
# can look at an individual level with
filter(kerri_data,id=="27233665")
#' some data are GMT some are GMT + 2, some are unknown
#' GMT+2
#' 5008, AG313, AG314, AG329, AG330, AG331, AG332, AG349
#' AG350, AG351, AG352, AG353, AG356, AG382, AM220, AM222, AM226, AM227, AM233, AM234, AM235, AM240, AM264
#' AM267, AM272, AM295, AM86, AM87, AM88, AM89
#' AM22 has seconds listed for some time stamps so do AM227, AM234, AM235, AM240, AM264, AM267, AM272
#' GMT
#' Ingelheim, 22959306, 27230695, 27233665, 33640, 33798
#' Unknown
#' LFV_009, X009
#'
#' Some data have time arranged from most recent
#' Ingelheim
# all of the data is in the format of day-month-year
target1 <- c("22959306", "27230695", "27233665")
test1 <- kerri_data %>% filter(id %in% target1)
test1$New_time<-parse_date_time(x=test1$time,c("%d/%m/%Y %H:%M"))
target2 <- c("5008", "AG313", "AG314", "AG329", "AG330", "AG331", "AG332", "AG349", "AG350", "AG351", "AG352",
"AG353", "AG356", "AG382", "AM220", "AM222", "AM226", "AM227", "AM233", "AM234", "AM235", "AM240",
"AM264", "AM267", "AM272", "AM295", "AM86", "AM87", "AM88", "AM89")
test2 <- kerri_data %>% filter(id %in% target2)
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M:%S"), tz = "africa/johannesburg")
target2
test2 <- kerri_data %>% filter(id %in% target2)
test2
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M:%S"), tz = "africa/johannesburg")
test2$New_time<-parse_date_time(x=test2$time,c("%d/%m/%Y %H:%M"), tz = "africa/johannesburg")
#' find out which dates failed to parse
which(is.na(test2$New_time))
test2[16973,]
test3 <-filter(test2,is.na(New_time))
levels(as.factor(test3$id))
levels(kerri_data$id)
levels(as.factor(kerri_data$id))
