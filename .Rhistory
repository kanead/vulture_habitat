levels(as.factor(trk3$ID))
length(levels(as.factor(trk3$ID)))
#' remove the resultant NA column that occurs after the split
trk3 <- dplyr::select(trk3, x, y, date, ID)
head(trk3)
#' turn it back into a trk
trk4 <-
mk_track(
trk3,
.x = x,
.y = y,
.t = date,
id = ID,
crs = CRS(
"+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs"
)
)
trk4
#' Calculate home range size for data that is regularised
mcps <- trk4 %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
dplyr::select(id, mcparea) %>% unnest()
mcps$area <- mcps$area / 1000000
mcp_95 <- mcps %>% arrange(id)
mcp_95
#' Same for KDE
kde <- trk4 %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
dplyr::select(id, kdearea) %>% unnest()
kde$kdearea <-  kde$kdearea / 1000000
kde_95 <- kde %>% arrange(id)
kde_95
#' combine the summary stats
data_summary$duration <- duration
data_summary$min_time <- min_time$time
data_summary$max_time <- max_time$time
data_summary$kde <- kde_95$kdearea
data_summary$study <- "Swazi"
data_summary$species <- min_time$species
data_summary
data_summary$mcps <- mcp_95$area
#' can export this data summary
write.csv(data_summary, file="track_resolution_summary/swazi_data_summary.csv", row.names = FALSE)
install.packages("nlrx")
library(nlrx)
nl <- nl(
nlversion = "6.0.4",
nlpath = "C:/Program Files/NetLogo 6.0.4/",
modelpath = "C:/Program Files/NetLogo 6.0.4/app/models/Sample Models/Biology",
jvmem = 1024
)
nl <- nl(
nlversion = "6.0.4",
nlpath = "C:/Program Files/NetLogo 6.0.4/",
modelpath = "C:/Program Files/NetLogo 6.0.4/app/models/Sample Models/Biology",
jvmmem = 1024
)
#' attaching an experiment
nl@experiment <-
experiment(
expname = "nlrx_ants_sobol",
outpath = "C:/Users/Adam/Documents/Science/Methods & Stats/nlrx package",
repetition = 1,
tickmetrics = "false",
idsetup = "setup",
idgo = "go",
runtime = 0,
stopcond = "not any? patches with [food > 0]",
metrics = c("ticks"),
variables = list(
"population" = list(min = 10, max = 200, qfun = "qunif"),
"diffusion-rate" = list(min = 1, max = 99, qfun = "qunif"),
"evaporation-rate" = list(min = 1, max = 99),
qfun = "qunif"
)
)
#' attaching a Sobol simdesign
nl@simdesign <- simdesign_sobol(nl=nl,samples=1000,sobolorder = 2,sobolnboot = 100,sobolconf = 0.95,nseeds = 6,precision = 3)
#' attaching a Sobol simdesign
nl@simdesign <- simdesign_sobol(nl=nl,samples=1000,sobolorder = 2,sobolnboot = 100,sobolconf = 0.95,nseeds = 6,precision = 3)
#' attaching a Sobol simdesign
nl@simdesign <-
simdesign_sobol(
nl = nl,
samples = 1000,
sobolorder = 2,
sobolnboot = 100,
sobolconf = 0.95,
nseeds = 6,
precision = 3
)
#' attaching a Sobol simdesign
nl@simdesign <-
simdesign_sobol(
nl = nl,
samples = 1000,
sobolorder = 2,
sobolnboot = 100,
sobolconf = 0.95,
nseeds = 6,
precision = 3
)
#' attaching an experiment
nl@experiment <-
experiment(
expname = "nlrx_ants_sobol",
outpath = "C:/Users/Adam/Documents/Science/Methods & Stats/nlrx package",
repetition = 1,
tickmetrics = "false",
idsetup = "setup",
idgo = "go",
runtime = 0,
stopcond = "not any? patches with [food > 0]",
metrics = c("ticks"),
variables = list(
"population" = list(min = 10, max = 200, qfun = "qunif"),
"diffusion-rate" = list(min = 1, max = 99, qfun = "qunif"),
"evaporation-rate" = list(min = 1, max = 99),
qfun = "qunif"
)
)
#' attaching a Sobol simdesign
nl@simdesign <-
simdesign_sobol(
nl = nl,
samples = 1000,
sobolorder = 2,
sobolnboot = 100,
sobolconf = 0.95,
nseeds = 6,
precision = 3
)
nl <- nl(
nlversion = "6.0.4",
nlpath = "C:/Program Files/NetLogo 6.0.4/",
modelpath = "C:/Program Files/NetLogo 6.0.4/app/models/Sample Models/Biology",
jvmmem = 1024
)
#' attaching an experiment
nl@experiment <-
experiment(
expname = "nlrx_ants_sobol",
outpath = "C:/Users/Adam/Documents/Science/Methods & Stats/nlrx package",
repetition = 1,
tickmetrics = "false",
idsetup = "setup",
idgo = "go",
runtime = 0,
stopcond = "not any? patches with [food > 0]",
metrics = c("ticks"),
variables = list(
"population" = list(min = 10, max = 200, qfun = "qunif"),
"diffusion-rate" = list(min = 1, max = 99, qfun = "qunif"),
"evaporation-rate" = list(min = 1, max = 99),
qfun = "qunif"
)
)
#' attaching a Sobol simdesign
nl@simdesign <-
simdesign_sobol(
nl = nl,
samples = 1000,
sobolorder = 2,
sobolnboot = 100,
sobolconf = 0.95,
nseeds = 6,
precision = 3
)
nl <- nl(
nlversion = "6.0.4",
nlpath = "C:/Program Files/NetLogo 6.0.4/",
modelpath = "C:/Program Files/NetLogo 6.0.4/app/models/Sample Models/Biology/Ants.nlogo",
jvmmem = 1024
)
#' attaching an experiment
nl@experiment <-
experiment(
expname = "nlrx_ants_sobol",
outpath = "C:/Users/Adam/Documents/Science/Methods & Stats/nlrx package",
repetition = 1,
tickmetrics = "false",
idsetup = "setup",
idgo = "go",
runtime = 0,
stopcond = "not any? patches with [food > 0]",
metrics = c("ticks"),
variables = list(
"population" = list(min = 10, max = 200, qfun = "qunif"),
"diffusion-rate" = list(min = 1, max = 99, qfun = "qunif"),
"evaporation-rate" = list(min = 1, max = 99),
qfun = "qunif"
)
)
#' attaching a Sobol simdesign
nl@simdesign <-
simdesign_sobol(
nl = nl,
samples = 1000,
sobolorder = 2,
sobolnboot = 100,
sobolconf = 0.95,
nseeds = 6,
precision = 3
)
nl <- nl(
nlversion = "6.0.4",
nlpath = "C:/Program Files/NetLogo 6.0.4/",
modelpath = "C:/Program Files/NetLogo 6.0.4/app/models/Sample Models/Biology/Wolf Sheep Predation.nlogo",
jvmmem = 1024
)
#' attaching an experiment
nl@experiment <- experiment(expname="wolf-sheep",
outpath=outpath,
repetition=1,
tickmetrics="true",
idsetup="setup",
idgo="go",
runtime=50,
evalticks=seq(40,50),
metrics=c("count sheep", "count wolves", "count patches with [pcolor = green]"),
variables = list('initial-number-sheep' = list(min=50, max=150, qfun="qunif"),
'initial-number-wolves' = list(min=50, max=150, qfun="qunif")),
constants = list("model-version" = "\"sheep-wolves-grass\"",
"grass-regrowth-time" = 30,
"sheep-gain-from-food" = 4,
"wolf-gain-from-food" = 20,
"sheep-reproduce" = 4,
"wolf-reproduce" = 5,
"show-energy?" = "false"))
outpath <- file.path("C:/Users/Adam/Documents/Science/Methods & Stats/nlrx package")
#' attaching an experiment
nl@experiment <- experiment(expname="wolf-sheep",
outpath=outpath,
repetition=1,
tickmetrics="true",
idsetup="setup",
idgo="go",
runtime=50,
evalticks=seq(40,50),
metrics=c("count sheep", "count wolves", "count patches with [pcolor = green]"),
variables = list('initial-number-sheep' = list(min=50, max=150, qfun="qunif"),
'initial-number-wolves' = list(min=50, max=150, qfun="qunif")),
constants = list("model-version" = "\"sheep-wolves-grass\"",
"grass-regrowth-time" = 30,
"sheep-gain-from-food" = 4,
"wolf-gain-from-food" = 20,
"sheep-reproduce" = 4,
"wolf-reproduce" = 5,
"show-energy?" = "false"))
#' attaching a Sobol simdesign
nl@simdesign <- simdesign_lhs(nl=nl,
samples=100,
nseeds=3,
precision=3)
#' run simulations
results <- run_nl_all(nl)
# Attach results to nl object:
setsim(nl, "simoutput") <- results
# Write output to outpath of experiment within nl
write_simoutput(nl)
# Do further analysis:
analyze_nl(nl)
?experiment
head(results)
tail(results)
max(results$`[run number]`)
?simdesign_lhs
?simdesign
?experiment
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
length(files)
mydata1 <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
mydata1$long <- as.numeric(mydata1$long)
mydata1$lat <- as.numeric(mydata1$lat)
mydata <- mydata1 %>% drop_na()
rm(mydata1)
#' filter the data to remove obvious outliers
mydata <- dplyr::filter(mydata1, lat < 20 & lat > -40 & long > 15 & long < 50)
#' filter the data to remove obvious outliers
mydata <- dplyr::filter(mydata, lat < 20 & lat > -40 & long > 15 & long < 50)
# Swaziland Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
library(adehabitatLT)
# swazi
# select swazi data which is the data we tracked in Swaziland
swazi_data <- filter(mydata, study == "swazi")
swazi_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-swazi_data %>% dplyr::select(time, long, lat, id) %>%
duplicated
sum(ind2)
# remove them
swazi_data$dups <- ind2
swazi_data <- filter(swazi_data,dups=="FALSE")
swazi_data
# set the time column
levels(factor(swazi_data$id))
# can look at an individual level with
(filter(swazi_data,id=="ID1"))
# all of the data is in the format of day-month-year
swazi_data$New_time<-parse_date_time(x=swazi_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
swazi_data <- dplyr::select(swazi_data, New_time,long,lat,id,species,study)
swazi_data <- rename(swazi_data, time = New_time)
swazi_data
#' estimate vmax for threshold speed
#' names(swazi_data)[names(swazi_data) == 'time'] <- 'DateTime'
#' speed.est.data <- swazi_data %>% filter(id == "ID2") %>%  select(id,DateTime,lat,long)
#' speed.est.data$qi = 5
#' est.vmax(sdata = data.frame(speed.est.data))
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(swazi_data)[names(swazi_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(swazi_data), vmax = 100, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
swazi_data <- SDLfilterData
names(swazi_data)[names(swazi_data) == 'DateTime'] <- 'time'
# check the minimum time and the maximum time
min_time <- swazi_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- swazi_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' determine the length of time each bird was tracked for
duration <- difftime(max_time$time, min_time$time, units = "days");duration
#' export the cleaned tracks
#' write the function
#' customFun  = function(DF) {
#'   write.csv(DF,paste0("",unique(DF$id),".csv"),row.names = FALSE)
#'   return(DF)
#' }
#' apply the function to the data set by bird ID
#' swazi_data %>%
#'  group_by(id) %>%
#'  dplyr::select(time, long, lat, id, species, study) %>%
#'  do(customFun(.))
#' try the amt package
trk <-
mk_track(
swazi_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326"))  %>%
transform_coords(
sp::CRS( #' we can transform the CRS of the data to an equal area projection
#' https://epsg.io/102022
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
#' summarise the sampling rate
data_summary <- trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest %>% arrange(id) ; data_summary
#' measure the time difference between points for each bird ID using dplyr
#' - Group your data by ID
#' - Compute time diffs between each timestamp in your group (the 1st time diff is NA)
#' - Create a new ID that counts no. of prior time gaps that are large (e.g. > 24 hours)
#' - Split the ID into newID by using an underscore separator
length(levels(as.factor(trk$id)))
#' need to add the arrange function here otherwise the order gets messed up
trk2 <- trk %>%
group_by(id) %>%
mutate(timeDiff = c(NA, difftime(tail(t_, -1), head(t_, -1), units = "hours"))) %>%
mutate(newID = paste(id, cumsum(!is.na(timeDiff) &
timeDiff > 24), sep = "_")) %>% arrange(id, t_) %>%
ungroup()
head(trk2)
tail(trk2)
#' check the number of newIDs
levels(as.factor(trk2$newID))
length(levels(as.factor(trk2$newID)))
#' how long are the tracks now that some of them have been split
sapply(split(trk2$x_, trk2$newID), length)
#' create a trajectory object using adehabitatLT
trk_ltraj <-
as.ltraj(xy = trk2[, c("x_", "y_")],
date = trk2$t_,
id = trk2$newID)
#' rediscretization of the trajectory
tstep <-
14400 # time step we want for the rediscretization, in seconds, 14400 secs = 4 hours
newtr <- redisltraj(trk_ltraj, u = tstep, type = "time")
head(newtr[1])
head(newtr[2])
class(newtr)
#' convert to class data frame
trk3 <- ld(newtr)
head(trk3)
class(trk3$date)
#' we should group the IDs that were split if they had big gaps back together into their original ID structure
#' this involves accessing the name of the new ID that occurs before the underscore
trk3 <- separate(trk3,
col = id,
sep = "_",
into = c("ID", "NA"))
head(trk3)
levels(as.factor(trk3$ID))
length(levels(as.factor(trk3$ID)))
#' remove the resultant NA column that occurs after the split
trk3 <- dplyr::select(trk3, x, y, date, ID)
head(trk3)
#' turn it back into a trk
trk4 <-
mk_track(
trk3,
.x = x,
.y = y,
.t = date,
id = ID,
crs = CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
trk4
trk4
# Keep only the id column and the x and y coordinates
mydata.sp <- trk4[, c("id", "x_", "y_")]
mydata.sp
# Define the coordinates
coordinates(mydata.sp) <- c("x_", "y_")
mydata.sp
proj4string(mydata.sp) <- CRS( "+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
mydata.sp
library(adehabitatHR)
kernel.ref <- kernelUD(mydata.sp, h = "href")  # href = the reference bandwidth
image(kernel.ref) # plot
# measure the size of the kernel
mydata.kernel.poly <- getverticeshr(kernel.ref, percent = 95, unout = "km2")
print(mydata.kernel.poly)  # returns the area of each polygon
#' Calculate home range size for data that is regularised
mcps <- trk4 %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
dplyr::select(id, mcparea) %>% unnest()
mcps$area <- mcps$area / 1000000
mcp_95 <- mcps %>% arrange(id)
mcp_95
#' Same for KDE
kde <- trk4 %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
dplyr::select(id, kdearea) %>% unnest()
kde$kdearea <-  kde$kdearea / 1000000
kde_95 <- kde %>% arrange(id)
kde_95
kernel.ref <- kernelUD(mydata.sp, h = "LSCV")  # href = the reference bandwidth
image(kernel.ref) # plot
kernel.ref <- kernelUD(mydata.sp, h = "href")  # href = the reference bandwidth
image(kernel.ref) # plot
# measure the size of the kernel
mydata.kernel.poly <- getverticeshr(kernel.ref, percent = 95, unout = "km2")
print(mydata.kernel.poly)  # returns the area of each polygon
# export it
writeOGR(mydata.kernel.poly, dsn= getwd(), "swazihr95", driver = "ESRI Shapefile",overwrite_layer=TRUE)
library(rgdal)
# export it
writeOGR(mydata.kernel.poly, dsn= getwd(), "swazihr95", driver = "ESRI Shapefile",overwrite_layer=TRUE)
class(mydata.kernel.poly)
mydata.kernel.poly$area
mydata.kernel.poly$id
mydata.kernel.poly
kernel.ref
kernel.ref
kernel.ref$ID1$ud
kernel.ref$ID2$ud
mydata.sp
#' using custom function
computeKDE <- function(xy, percent = 95) {
require(pracma)
mykde <- kde(x = xy, compute.cont = TRUE)
mycontour <- with(mykde, contourLines(x = eval.points[[1]], y = eval.points[[2]],
z = estimate, levels = cont[percent]))
myarea = sum(sapply(mycontour, function(c) abs(polyarea(c$x, c$y)))) * 1e-06
return(list(contour = mycontour, area = myarea))
}
computeKDE(mydata.sp, percent = 95)
#' using custom function
computeKDE <- function(xy, percent = 95) {
require(pracma)
require(ks)
mykde <- kde(x = xy, compute.cont = TRUE)
mycontour <- with(mykde, contourLines(x = eval.points[[1]], y = eval.points[[2]],
z = estimate, levels = cont[percent]))
myarea = sum(sapply(mycontour, function(c) abs(polyarea(c$x, c$y)))) * 1e-06
return(list(contour = mycontour, area = myarea))
}
computeKDE(mydata.sp, percent = 95)
mydata.sp
computeKDE(mydata.sp, percent = 95)
kerneloverlaphr(mydata.sp,method = "BA", percent = 95)
kerneloverlaphr(kernel.ref,method = "BA", percent = 95)
kerneloverlaphr(kernel.ref,method = "HR", percent = 95)
