#' Check for duplicated observations (ones with same lat, long, time,
#'  and individual identifier).
ind2 <- galligan_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
galligan_data$dups <- ind2
galligan_data <- filter(galligan_data, dups == "FALSE")
galligan_data
tail(galligan_data)
# can look at an individual level with
(filter(galligan_data, id == "143660"))
#' all of the data is in the format of day-month-year
#' time zone is UTC by default
galligan_data$New_time <-
parse_date_time(x = galligan_data$time, c("%d/%m/%Y %H:%M"))
# keep only the new time data
galligan_data <-
select(galligan_data, New_time, long, lat, id, species, study)
# set the time column
levels(factor(galligan_data$id))
galligan_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(galligan_data)[names(galligan_data) == 'time'] <- 'DateTime'
galligan_data <- rename(galligan_data, time = New_time)
length(SDLfilterData$DateTime)
#' rename everything as before
galligan_data <- SDLfilterData
SDLfilterData <-
ddfilter.speed(data.frame(galligan_data), vmax = 70, method = 1)
names(galligan_data)[names(galligan_data) == 'DateTime'] <- 'time'
# check the minimum time and the maximum time
min_time <- galligan_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- galligan_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' determine the length of time each bird was tracked for
duration <-difftime(max_time$time, min_time$time, units = "days"); duration
# try the amt package
trk <-
mk_track(
galligan_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
) %>%
transform_coords(
sp::CRS(
#' we can transform the CRS of the data to an equal area projection
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
#' summarise the sampling rate
data_summary <- trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest %>% arrange(id)
#' Calculate home range size for data that is not regularised
mcps <- trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
mcps$area <- mcps$area / 1000000
mcp_95 <- mcps %>% arrange(id)
#' Same for KDE
kde <- trk %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
select(id, kdearea) %>% unnest()
kde$kdearea <-  kde$kdearea / 1000000
kde_95 <- kde %>% arrange(id)
#' combine the summary stats
data_summary$duration <- duration
data_summary$min_time <- min_time$time
data_summary$max_time <- max_time$time
data_summary$kde <- kde_95$kdearea
data_summary$mcps <- mcp_95$area
data_summary$species <- min_time$species
data_summary$study <- "galligan"
data_summary
617933 -  159279
write.csv(data_summary, file="track_resolution_summary/galligan_data_summary.csv", row.names = FALSE)
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "track_resolution_summary"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
res_data <- files %>%
# read in all the files, appending the path before the filename
map( ~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
res_data
levels(res_data$study)
levels(as.factor(res_data$study))
res_data$region <-
if_else(
res_data$study == "CK" |
res_data$study == "masai" |
res_data$study == "north" |
res_data$study == "Corinne_mara" ,
"east",
"south"
)
#'export the combined summary stats table for the temporal resolution of the data
write.csv(res_data, file = "results/summary_all_tracks.csv", row.names = FALSE)
nonWantedLevels <- c("AG382", "AM89", "AM88", "AM87")
subset <- res_data %>% dplyr::filter(!id %in% nonWantedLevels)
levels(as.factor(subset$id))
length(levels(as.factor(subset$id)))
length(levels(as.factor(subset$study)))
#' how long were the birds tracked for?
p0 <-
ggplot(data = subset,
mapping = aes(
x = species,
y = duration,
fill = factor(species)
)) + geom_boxplot(alpha = 0.5, show.legend = FALSE) + ylab("duration (days)") +
theme_bw()
duration_data_all <- p0 + theme(legend.position = "none")
duration_data_all
#' extract just the gyps for all durations
species_to_keep <- c("cv", "rv", "wb")
gyps <- subset %>% dplyr::filter(species %in% species_to_keep)
#' how long were the gyps tracked for
duration_data_gyps <- ggplot(data = gyps,
mapping = aes(
x = species,
y = duration,
fill = factor(species)
)) + geom_boxplot(alpha = 0.5, show.legend = FALSE) + ylab("duration (days)") +
theme_bw() + theme(
legend.position = "none",
axis.text = element_text(size = 20),
axis.title = element_text(size = 20)
)
duration_data_gyps
ggsave("plots/duration_data_gyps.png")
#' keep only the birds that were tracked for over a year
year <- dplyr::filter(subset, duration > 365)
#' boxplots of the KDEs by speices
ggplot(data = year, mapping = aes(x = species, y = kde)) + geom_boxplot() + ylab("KDE 95%")
#' boxplots of the KDEs by region
ggplot(data = year, mapping = aes(x = region, y = kde)) + geom_boxplot() + ylab("KDE 95%")
#' group by species and get the mean kde
year %>% group_by(species) %>% summarize(mean_kde = mean(kde))
#' group by species and get the max kde
year %>% group_by(species) %>% summarize(max_kde = max(kde))
#' group by species and get the median kde
year %>% group_by(species) %>% summarize(median_kde = median(kde))
#' extract one species and get its max kde
dplyr::filter(year, species == "cv") %>% summarize(maxkde = max(kde))
#' group by region and get the median kde
year %>% group_by(region) %>% summarize(median_kde = median(kde))
#' subset to Gyps that were tracked for over a year
gyps_year <- year %>% dplyr::filter(species == c("cv", "rv", "wb"))
p1 <-
ggplot(data = gyps_year,
mapping = aes(
x = species,
y = kde,
fill = factor(species)
)) + geom_boxplot(alpha = 0.5, show.legend = FALSE) + ylab("KDE 95% km2") + theme_bw()
year
year
levels(as.factor(year$species))
year %>% dplyr::filter(species == c("cv", "rv", "wb"))
year %>% dplyr::filter(species == c("cv", "rv", "wb"))
#' keep only the birds that were tracked for over a year
year <- dplyr::filter(subset, duration > 365)
#' subset to Gyps that were tracked for over a year
gyps_year <- year %>% dplyr::filter(species == c("cv", "rv", "wb"))
p1 <-
ggplot(data = gyps_year,
mapping = aes(
x = species,
y = kde,
fill = factor(species)
)) + geom_boxplot(alpha = 0.5, show.legend = FALSE) + ylab("KDE 95% km2") + theme_bw()
p1
#' keep only the birds that were tracked for over a year
year <- dplyr::filter(subset, duration > 365 & species == c("cv", "rv", "wb"))
#' keep only the birds that were tracked for over a year
year <- dplyr::filter(subset, duration > 365)
#' subset to Gyps that were tracked for over a year
gyps_year <- year %>% dplyr::filter(species %in% species_to_keep)
p1 <-
ggplot(data = gyps_year,
mapping = aes(
x = species,
y = kde,
fill = factor(species)
)) + geom_boxplot(alpha = 0.5, show.legend = FALSE) + ylab("KDE 95% km2") + theme_bw()
p1
#' remove outliers
# compute lower and upper whiskers
ylim1 = boxplot.stats(gyps_year$kde)$stats[c(1, 5)]
# scale y limits based on ylim1
p2 = p1 + coord_cartesian(ylim = ylim1 * 1.05) + theme(
legend.position = "none",
axis.text = element_text(size = 20),
axis.title = element_text(size = 20)
)
p2
kde_gyps_year = p1 + coord_cartesian(ylim = ylim1 * 1.05) + theme(
legend.position = "none",
axis.text = element_text(size = 20),
axis.title = element_text(size = 20)
)
kde_gyps_year
ggsave("plots/kde_gyps_year.png")
#' plot white backs by region
wb <- year %>% dplyr::filter(species == c("wb"))
p3 <-
ggplot(data = wb,
mapping = aes(
x = region,
y = kde,
fill = factor(region)
)) + geom_boxplot(alpha = 0.5, show.legend = FALSE) + ylab("KDE 95% km2") + theme_bw()
p3
#' remove outliers
# compute lower and upper whiskers
ylim1 = boxplot.stats(wb$kde)$stats[c(1, 5)]
#' remove outliers
# compute lower and upper whiskers
ylim1 = boxplot.stats(wb$kde)$stats[c(1, 5)]
# scale y limits based on ylim1
wb_region = p3 + coord_cartesian(ylim = ylim1 * 1.05) + theme(
legend.position = "none",
axis.text = element_text(size = 20),
axis.title = element_text(size = 20)
)
wb_region
ggsave("plots/wb_region.png")
#' group by species and get the mean duration
year %>% group_by(species) %>% summarize(mean_duration = mean(duration))
#' group by species and get the mean duration
gyps %>% group_by(species) %>% summarize(mean_duration = mean(duration))
#' get the mean duration
gyps %>% summarize(mean_duration = mean(duration))
#' subset to Gyps that were tracked for over a year
gyps_year <- year %>% dplyr::filter(species %in% species_to_keep)
length(gyps_year$id)
gyps_year$species
#' group by region and get the median kde
year %>% group_by(region) %>% summarize(median_kde = median(kde))
#' group by species and get the median kde
year %>% group_by(species) %>% summarize(median_kde = median(kde))
#' Code for extracting summary statistics from the comparative vulture project
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "track_resolution_summary"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
res_data <- files %>%
# read in all the files, appending the path before the filename
map( ~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
res_data
#' associate a broad geographic location with each study
#' CK = east
#' masai = east
#' north = east
#' Corinne_mara = east
#' GA_Namibia = south
#' inter = south
#' Kerri = south
#' mend_Namibia = south
#' Morgan = south
#' Swazi = south
#' andre = south
#' ralph = south
#' glynn = south
#' orr = south
#' galligan = south
#' Schabo = south
res_data$region <-
if_else(
res_data$study == "CK" |
res_data$study == "masai" |
res_data$study == "north" |
res_data$study == "Corinne_mara" ,
"east",
"south"
)
#'export the combined summary stats table for the temporal resolution of the data
write.csv(res_data, file = "results/summary_all_tracks.csv", row.names = FALSE)
#' Code for extracting summary statistics from the comparative vulture project
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "track_resolution_summary"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
res_data <- files %>%
# read in all the files, appending the path before the filename
map( ~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
res_data
#' associate a broad geographic location with each study
#' CK = east
#' masai = east
#' north = east
#' Corinne_mara = east
#' GA_Namibia = south
#' inter = south
#' Kerri = south
#' mend_Namibia = south
#' Morgan = south
#' Swazi = south
#' andre = south
#' ralph = south
#' glynn = south
#' orr = south
#' galligan = south
#' Schabo = south
res_data$region <-
if_else(
res_data$study == "CK" |
res_data$study == "masai" |
res_data$study == "north" |
res_data$study == "Corinne_mara" ,
"east",
"south"
)
#'export the combined summary stats table for the temporal resolution of the data
write.csv(res_data, file = "results/summary_all_tracks.csv", row.names = FALSE)
res_data
tal(res_data)
tail(res_data)
wb_region
#' group by region and get the median kde for the white backs
wb %>% group_by(region) %>% summarize(median_kde = median(kde))
?hr_kde
#' how many data points?
sum(gyps$n)
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
length(files)
mydata1 <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
mydata1$long <- as.numeric(mydata1$long)
mydata1$lat <- as.numeric(mydata1$lat)
mydata <- mydata1 %>% drop_na()
#' filter the data to remove obvious outliers
mydata <- dplyr::filter(mydata1, lat < 20 & lat > -40 & long > 15 & long < 50)
head(mydata)
tail(mydata)
summary(mydata)
str(mydata)
levels(as.factor(mydata$study))
#' How many countries does the bird track overlap with?
#' Swaziland Vulture Tracking Dataset
#' load packages
library(rworldmap)
library(sp)
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# swazi
# select swazi data which is the data we tracked in Swaziland
swazi_data <- filter(mydata, study == "swazi")
swazi_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-swazi_data %>% select(time, long, lat, id) %>%
duplicated
sum(ind2)
# remove them
swazi_data$dups <- ind2
swazi_data <- filter(swazi_data,dups=="FALSE")
swazi_data
# set the time column
levels(factor(swazi_data$id))
# can look at an individual level with
(filter(swazi_data,id=="ID1"))
# all of the data is in the format of day-month-year
swazi_data$New_time<-parse_date_time(x=swazi_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
swazi_data <- select(swazi_data, New_time,long,lat,id,species,study)
swazi_data <- rename(swazi_data, time = New_time)
swazi_data
#' estimate vmax for threshold speed
#' names(swazi_data)[names(swazi_data) == 'time'] <- 'DateTime'
#' speed.est.data <- swazi_data %>% filter(id == "ID2") %>%  select(id,DateTime,lat,long)
#' speed.est.data$qi = 5
#' est.vmax(sdata = data.frame(speed.est.data))
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(swazi_data)[names(swazi_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(swazi_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
swazi_data <- SDLfilterData
names(swazi_data)[names(swazi_data) == 'DateTime'] <- 'time'
install.packages("rworldmap")
#' How many countries does the bird track overlap with?
#' Swaziland Vulture Tracking Dataset
#' load packages
library(rworldmap)
#' get the map of the world
m = getMap()
coordinates(swazi_data) = ~long+lat
proj4string(swazi_data) = proj4string(m)
over(d,m)$NAME
over(swazi_data,m)$NAME
d$country = over(swazi_data,m)$NAME
swazi_data$country = over(swazi_data,m)$NAME
levels(swazi_data$country)
#' I can add the NAME to the source points:
swazi_data <- swazi_data %>% drop_na()
#' I can add the NAME to the source points:
swazi_data$country = over(swazi_data,m)$NAME
head(swazi_data$country )
over(swazi_data,m)$NAME
head(swazi_data)
levels(over(swazi_data,m)$NAME)
levels(over(swazi_data,m)$NAME, na.rm = T)
head(swazi_data$country)
swazi_data$country <- droplevels(swazi_data$country)
head(swazi_data$country)
levels(swazi_data$country)
countries <- levels(swazi_data$country)
write.csv(countries, file = "results/swazi_countries_overlap.csv", row.names = F)
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
length(files)
mydata1 <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
mydata1$long <- as.numeric(mydata1$long)
mydata1$lat <- as.numeric(mydata1$lat)
mydata <- mydata1 %>% drop_na()
#' filter the data to remove obvious outliers
mydata <- dplyr::filter(mydata1, lat < 20 & lat > -40 & long > 15 & long < 50)
head(mydata)
tail(mydata)
summary(mydata)
str(mydata)
levels(as.factor(mydata$study))
x <- c(1:100)
r <- 2
y <- - r*x^2 + r*x
plot(x,y)
x <- c(1:10)
r <- 2
y <- - r*x^2 + r*x
plot(x,y)
x <- c(50:100)
r <- 2
y <- - r*x^2 + r*x
plot(x,y)
P = 1
r = 2
t = 100
y = P * e^(r*t)
P = 1
r = 2
t = 100
y = P * exp(r*t)
y
P = 1
r = 2
t = 2
y = P * exp(r*t)
y
P = 1
r = 2
t = 1
y = P * exp(r*t)
y
P = 1
r = 1
t = 1
y = P * exp(r*t)
y
P = 1
t = 2
y = P * exp(r*t)
y
r = 1
