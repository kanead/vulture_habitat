data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
mydata <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
#' filter the data to remove obvious outliers
mydata <- filter(mydata, lat < 20 & lat > -40 & long > 10)
head(mydata)
tail(mydata)
str(mydata)
levels(as.factor(mydata$study))
# Corinne Kendall's Tanzania Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# ck_tanz
# select ck_tanz data which is Corinne's data from everything
ck_tanz_data <- filter(mydata, study == "ck_tanz")
ck_tanz_data
#' Check for duplicated observations (ones with same lat, long, time,
#'  and individual identifier).
ind2 <- ck_tanz_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
ck_tanz_data$dups <- ind2
ck_tanz_data <- filter(ck_tanz_data, dups == "FALSE")
ck_tanz_data
# set the time column
levels(factor(ck_tanz_data$id))
# can look at an individual level with
(filter(ck_tanz_data, id == "#109018542"))
# all of the data is in the format of day-month-year
ck_tanz_data$New_time <-
parse_date_time(x = ck_tanz_data$time, c("%d/%m/%Y %H:%M"))
# keep only the new time data
ck_tanz_data <-
select(ck_tanz_data, New_time, long, lat, id, species, study)
ck_tanz_data <- rename(ck_tanz_data, time = New_time)
ck_tanz_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(ck_tanz_data)[names(ck_tanz_data) == 'time'] <- 'DateTime'
SDLfilterData <-
ddfilter.speed(data.frame(ck_tanz_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
ck_tanz_data <- SDLfilterData
names(ck_tanz_data)[names(ck_tanz_data) == 'DateTime'] <- 'time'
# check the minimum time and the maximum time
min_time <- ck_tanz_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- ck_tanz_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' determine the length of time each bird was tracked for
difftime(max_time$time,min_time$time,units="days")
# try the amt package
trk <-
mk_track(
ck_tanz_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
) %>%
transform_coords(
sp::CRS( #' we can transform the CRS of the data to an equal area projection
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
#' summarise the sampling rate
trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest %>% arrange(id)
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class <- class(trk)
# nest by id
nesttrk <- trk %>% nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk <- trk %>% nest(-id) %>%
mutate(
dir_abs = map(data, direction_abs, full_circle = TRUE, zero = "N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_ = map(data, nsd)
) %>% unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk <- trk %>%
mutate(
week = week(t_),
month = month(t_, label = TRUE),
year = year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk) <- trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
#' some data points look a little off
#' we can identify them to investiage further and remove them
#' if needs be
filter(trk, id == "#199122325" & nsd_ < 1e+11)
trk <- trk  %>%
filter(!((id == "#199122325" & nsd_ > 1e+11)))
#' turn back to lat long
# try the amt package
trk_map <-
mk_track(
ck_tanz_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)
#' map the data
library(leaflet)
levels(as.factor(trk_map$id))
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(trk_map, id == "#199122325"),
lat = ~ y_,
lng = ~ x_,
color = "blue"
)
trk
#' plot all data on one map
ggplot(trk, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point()
#' turn back to lat long
# try the amt package
trk_map <-
mk_track(
ck_tanz_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)
#' remove outlier for plotting
trk_map <- trk_map  %>%
filter(!((id == "#199122325" & nsd_ > 1e+11)))
#' map the data
library(leaflet)
levels(as.factor(trk_map$id))
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(trk_map, id == "#199122325"),
lat = ~ y_,
lng = ~ x_,
color = "blue"
)
#' plot all data on one map
ggplot(trk, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point()
trk_map
#' plot all data on one map
ggplot(trk_map, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point()
#' remove the weird point from #199122325
trk_map <- trk_map  %>%
filter(!((id == "#199122325" & y_ < 1e+11)))
#' map the data
library(leaflet)
levels(as.factor(trk_map$id))
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(trk_map, id == "#199122325"),
lat = ~ y_,
lng = ~ x_,
color = "blue"
)
trk_map
#' plot all data on one map
ggplot(trk_map, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point()
trk_map <-
mk_track(
ck_tanz_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
)
#' remove the weird point from #199122325
trk_map <- trk_map  %>%
filter(!((id == "#199122325" & y_ < -10)))
#' map the data
library(leaflet)
levels(as.factor(trk_map$id))
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(trk_map, id == "#199122325"),
lat = ~ y_,
lng = ~ x_,
color = "blue"
)
#' plot all data on one map
ggplot(trk_map, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point()
#' plot all data on one map
ggplot(trk_map, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point() + xlab = "longitude" + ylab = "latitude"
#' plot all data on one map
ggplot(trk_map, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point() + xlab ("longitude")# + ylab = "latitude"
#' plot all data on one map
ggplot(trk_map, aes(x=x_, y=y_, color=as.factor(id)))+
geom_point() + xlab ("longitude") + ylab ("latitude")
install.packages("ggmap")
install.packages("ggmap")
library(ggmap)
qmplot(x_, y_, data = trk_map, maptype = "toner-lite", color = I("red"))
qmplot(x_, y_, data = trk_map, maptype = "toner-lite", color = as.factor(id))
ck_tanz_data
#' We can also use lat, long, which will allow us to determine
#' time of day
trk <- mk_track(ck_tanz_data, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
library(amt)
#' We can also use lat, long, which will allow us to determine
#' time of day
trk <- mk_track(ck_tanz_data, .x=long, .y=lat, .t=time, id = id,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
trk
?time_of_day
#' We can add a columns to each nested column of data using purrr::map
trk <- trk %>% nest(-id) %>%
mutate(
dir_abs = map(data, direction_abs, full_circle = TRUE, zero = "N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_ = map(data, nsd)
) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(trk, aes(x = tod_, y = log(sl))) +
geom_boxplot()+geom_smooth()+facet_wrap(~id)
?parse_date_time
ck_tanz_data$time
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
mydata <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
#' filter the data to remove obvious outliers
mydata <- filter(mydata, lat < 20 & lat > -40 & long > 10)
head(mydata)
tail(mydata)
str(mydata)
levels(as.factor(mydata$study))
# Corinne Kendall's Tanzania Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# ck_tanz
# select ck_tanz data which is Corinne's data from everything
ck_tanz_data <- filter(mydata, study == "ck_tanz")
ck_tanz_data
#' Check for duplicated observations (ones with same lat, long, time,
#'  and individual identifier).
ind2 <- ck_tanz_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
ck_tanz_data$dups <- ind2
ck_tanz_data <- filter(ck_tanz_data, dups == "FALSE")
ck_tanz_data
# set the time column
levels(factor(ck_tanz_data$id))
# can look at an individual level with
(filter(ck_tanz_data, id == "#109018542"))
#' all of the data is in the format of day-month-year
#' time zone is UTC by default
#' looks like the recorder starts at 4am UTC and records every hour until 5pm
#' one other GPS fix is taken at 22:00
ck_tanz_data$New_time <-
parse_date_time(x = ck_tanz_data$time, c("%d/%m/%Y %H:%M"))
# keep only the new time data
ck_tanz_data <-
select(ck_tanz_data, New_time, long, lat, id, species, study)
ck_tanz_data <- rename(ck_tanz_data, time = New_time)
ck_tanz_data
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(ck_tanz_data)[names(ck_tanz_data) == 'time'] <- 'DateTime'
SDLfilterData <-
ddfilter.speed(data.frame(ck_tanz_data), vmax = 70, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
ck_tanz_data <- SDLfilterData
names(ck_tanz_data)[names(ck_tanz_data) == 'DateTime'] <- 'time'
# check the minimum time and the maximum time
min_time <- ck_tanz_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- ck_tanz_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' determine the length of time each bird was tracked for
difftime(max_time$time,min_time$time,units="days")
# try the amt package
trk <-
mk_track(
ck_tanz_data,
.x = long,
.y = lat,
.t = time,
id = id,
species = species,
crs = CRS("+init=epsg:4326")
) %>%
transform_coords(
sp::CRS( #' we can transform the CRS of the data to an equal area projection
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
#' summarise the sampling rate
trk %>% nest(-id) %>% mutate(sr = map(data, summarize_sampling_rate)) %>%
dplyr::select(id, sr) %>% unnest %>% arrange(id)
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class <- class(trk)
# nest by id
nesttrk <- trk %>% nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk <- trk %>% nest(-id) %>%
mutate(
dir_abs = map(data, ~ direction_abs(., full_circle = TRUE, zero = "N")
%>% as_degree()) ,
dir_rel = map(data, ~ direction_rel(.)
%>% as_degree()),
sl = map(data, step_lengths),
nsd_ = map(data, nsd)
) %>% unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk <- trk %>%
mutate(
week = week(t_),
month = month(t_, label = TRUE),
year = year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk) <- trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
#' look at net-squared displacement
ggplot(trk, aes(x = t_, y = nsd_)) + geom_point() +
facet_wrap( ~ id, scales = "free")
#' some data points look a little off
#' we can identify them to investiage further and remove them
#' if needs be
filter(trk, id == "#199122325" & nsd_ < 1e+11)
trk <- trk  %>%
filter(!((id == "#199122325" & nsd_ > 1e+11)))
#' plot it again
ggplot(trk, aes(x = t_, y = nsd_)) + geom_point() +
facet_wrap( ~ id, scales = "free")
#+fig.height=12, fig.width=12
ggplot(trk_map, aes(x = dir_abs, y = ..density..)) +
geom_histogram(breaks = seq(0, 360, by = 20)) +
coord_polar(start = 0) + theme_minimal() +
scale_fill_brewer() + ylab("Density") + ggtitle("Angles Direct") +
scale_x_continuous(
"",
limits = c(0, 360),
breaks = seq(0, 360, by = 20),
labels = seq(0, 360, by = 20)
) +
facet_wrap(~ id)
#' ### Absolute angles (for each movement) relative to North
#' We could use a rose diagram (below) to depict the distribution of angles.
#+fig.height=12, fig.width=12
ggplot(trk, aes(x = dir_abs, y = ..density..)) +
geom_histogram(breaks = seq(0, 360, by = 20)) +
coord_polar(start = 0) + theme_minimal() +
scale_fill_brewer() + ylab("Density") + ggtitle("Angles Direct") +
scale_x_continuous(
"",
limits = c(0, 360),
breaks = seq(0, 360, by = 20),
labels = seq(0, 360, by = 20)
) +
facet_wrap(~ id)
#' ### Turning angles
#'
#' Note: a 0 indicates the animal continued to move in a straight line, a 180
#' indicates the animal turned around (but note, resting + measurement error often can
#' make it look like the animal turned around).
#+fig.height=12, fig.width=12
ggplot(trk, aes(x = dir_rel, y = ..density..)) +
geom_histogram(breaks = seq(-180, 180, by = 20)) +
coord_polar(start = 0) + theme_minimal() +
scale_fill_brewer() + ylab("Density") + ggtitle("Angles Direct") +
scale_x_continuous(
"",
limits = c(-180, 180),
breaks = seq(-180, 180, by = 20),
labels = seq(-180, 180, by = 20)
) +
facet_wrap(~ id)
ggplot(trk, aes(x = dir_rel)) +
geom_histogram(breaks = seq(-180, 180, by = 20)) +
theme_minimal() +
scale_fill_brewer() + ylab("Count") + ggtitle("Angles Relative") +
scale_x_continuous(
"",
limits = c(-180, 180),
breaks = seq(-180, 180, by = 20),
labels = seq(-180, 180, by = 20)
) + facet_wrap(~ id, scales = "free")
l = 250
M <- 0.00007 * L ^ 2.6609
l = 250
M <- 0.00007 * L ^ 2.6609
L = 250
M <- 0.00007 * L ^ 2.6609
M
L = c(250,400)
M <- 0.00007 * L ^ 2.6609
M
# 'Fecundity (number of eggs deposited) at size (1 cm length classes) for kelts was
#' calculated using the equation Fecundity = 60.67 × Length − 1238.49, derived for Erriff
#' sea trout in 1985 (O’Farrell et al. 1989).
L.cm <- (25,40)
F = 60.67 × L.cm − 1238.49
# 'Fecundity (number of eggs deposited) at size (1 cm length classes) for kelts was
#' calculated using the equation Fecundity = 60.67 × Length − 1238.49, derived for Erriff
#' sea trout in 1985 (O’Farrell et al. 1989).
L.cm <- (25,40)
Fec <- 60.67 × L.cm - 1238.49
# 'Fecundity (number of eggs deposited) at size (1 cm length classes) for kelts was
#' calculated using the equation Fecundity = 60.67 × Length − 1238.49, derived for Erriff
#' sea trout in 1985 (O’Farrell et al. 1989).
L_cm <- c(25,40)
Fec <- 60.67 × L_cm - 1238.49
Fec
# 'Fecundity (number of eggs deposited) at size (1 cm length classes) for kelts was
#' calculated using the equation Fecundity = 60.67 × Length − 1238.49, derived for Erriff
#' sea trout in 1985 (O’Farrell et al. 1989).
L_cm <- c(25, 40)
Fec <- 60.67 * L_cm - 1238.49
Fec
#' Length-Body Mass Relationships, length in cm, weight in grams
a <- -1.877
b <-  2.951
L_cm <- c(25, 40)
log(W) <- log(a) + b * log(L_cm) ;log(W)
log_W <- log(a) + b * log(L_cm) ;log_W
log(a)
a <- -1.877
b <-  2.951
L_cm <- c(25, 40)
W <- a * L_cm ^ b
W
L_cm
#' Length-Body Mass Relationships, length in cm, weight in grams
#' You need to raise your intercept to whatever base you're using but not your slope.
a <- 10^-1.877
b <-  2.951
L_cm <- c(25, 40)
W <- a * L_cm ^ b
W
L_cm <- c(25, 40, 60)
W <- a * L_cm ^ b
W
#' Values for lakes
a_lake <- 10 ^ -1.877
b_lake <-  2.951
L_cm <- c(25, 40, 60)
W <- a_lake * L_cm ^ b_lake
W
a_river <- 10 ^ -1.912
b_river <- 3.001
L_cm <- c(25, 40, 60)
W <- a_river * L_cm ^ b_river
W
