install.packages("mapview")
#' save the map## 'mapview' objects (image below)
library(mapview)
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(home_range_data, id == "ID1"),
lat = ~ y1_,
lng = ~ x1_,
color = "blue"
)
#' save the map## 'mapview' objects (image below)
m <- leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(home_range_data, id == "ID1"),
lat = ~ y1_,
lng = ~ x1_,
color = "blue"
)
getwd()
mapshot(m, file = paste0(getwd(), "/plots/Swazi_ID1.png"))
webshot::install_phantomjs()
mapshot(m, file = paste0(getwd(), "/plots/Swazi_ID1.png"))
#' save the map## 'mapview' objects (image below)
m <- leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(home_range_data, id == "ID2"),
lat = ~ y1_,
lng = ~ x1_,
color = "blue"
)
library(mapview)
mapshot(m, file = paste0(getwd(), "/plots/Swazi_ID2.png"))
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(home_range_data, id == "ID2"),
lat = ~ y1_,
lng = ~ x1_,
color = "blue"
)
mapshot(m, file = paste0(getwd(), "/plots/Swazi_ID2.png"))
mapshot(m, file = paste0(getwd(), "/plots/Swazi_ID2.png"))
home_range_trk
#' convert to UTM
coordinates(xy) <- c("x_", "y_")
#' convert to UTM
coordinates(home_range_trk) <- c("x_", "y_")
mcps <- home_range_trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
home_range_trk <-
mk_track(
home_range_data,
.x = x1_,
.y = y1_,
.t = t1_,
id = id,
crs = CRS("+init=epsg:4326")
)
mcps <- home_range_trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(mcps, aes(x = id, y = area)) + geom_point() +
geom_smooth()
#' Same for KDE
kde <- home_range_trk %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
select(id, kdearea) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(kde, aes(x = id, y = kdearea)) + geom_point() +
geom_smooth()
?hr_kde
head(home_range_data$x1_[home_range_data$id == "ID1"])
head(home_range_data$y1_[home_range_data$id == "ID1"])
#' convert data to UTM
#' https://gis.stackexchange.com/questions/209267/r-return-the-utm-zone-that-a-wgs84-point-belongs-to
home_range_trk$zone <-
floor((home_range_trk$x_ + 180) / 6) + 1
home_range_trk
coordinates(home_range_trk) <- c("x_", "y_")
proj4string(xy) <- CRS("+proj=longlat +datum=WGS84")  ## for example
proj4string(home_range_trk) <- CRS("+proj=longlat +datum=WGS84")  ## for example
str(home_range_trk$zone)
summary(home_range_trk$zone)
#' convert to Africa Albers Equal Area Conic
#' https://epsg.io/102022
res <-
spTransform(
xy,
CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m no_defs"
)
)
#' convert to Africa Albers Equal Area Conic
#' https://epsg.io/102022
res <-
spTransform(
home_range_trk,
CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m no_defs"
)
)
res <-
spTransform(
home_range_trk,
CRS("+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m no_defs"
)
)
#' convert to Africa Albers Equal Area Conic
#' https://epsg.io/102022
res <-
spTransform(
home_range_trk,
CRS("+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
res
head(res)
plot(Res)
plot(res)
res[,1]
res[,2]
res[,3]
class(res)
data.frame(res)
res_data <- data.frame(res)
res_data
coordinates(home_range_trk) <- c("x_", "y_")
res_data
mcps <- res_data %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
names(res_data)
home_range_trk <-
mk_track(
home_range_data,
.x = x1_,
.y = y1_,
.t = t1_,
id = id,
crs = CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
mcps <- home_range_trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(mcps, aes(x = id, y = area)) + geom_point() +
geom_smooth()
#' Same for KDE
kde <- home_range_trk %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
select(id, kdearea) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(kde, aes(x = id, y = kdearea)) + geom_point() +
geom_smooth()
home_range_trk
names(res_data)
home_range_trk <-
mk_track(
res_data,
.x = x1_,
.y = y1_,
.t = t1_,
id = id,
crs = CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
names(res_data)
home_range_trk <-
mk_track(
res_data,
.x = x_,
.y = y_,
.t = t_,
id = id,
crs = CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
home_range_trk
mcps <- home_range_trk %>% nest(-id) %>%
mutate(mcparea = map(data, ~ hr_mcp(., levels = c(0.95)) %>% hr_area)) %>%
select(id, mcparea) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(mcps, aes(x = id, y = area)) + geom_point() +
geom_smooth()
#' Same for KDE
kde <- home_range_trk %>% nest(-id) %>%
mutate(kdearea = map(data, ~ hr_kde(., levels = c(0.95)) %>% hr_area)) %>%
select(id, kdearea) %>% unnest()
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(kde, aes(x = id, y = kdearea)) + geom_point() +
geom_smooth()
#' map the data
library(leaflet)
levels(as.factor(home_range_data$id))
leaflet() %>% addTiles() %>%
addCircleMarkers(
data = filter(home_range_data, id == "ID2"),
lat = ~ y1_,
lng = ~ x1_,
color = "blue"
)
mcps
?hr_mcp
home_range_trk
#' We can add a columns to each nested column of data using purrr::map
trk<-home_range_trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
trk
sqrt(675639)
#########################################################################
#' Vulture comparative analysis
#' tutorials here https://www.jessesadler.com/post/gis-with-r-intro/
#' and here https://www.r-spatial.org/
#' 06 November 2018
#' 1_load_data - this loads in all of the tracking data and binds it
#########################################################################
#' Load the required packages
library(readr)
library(tidyverse)
#' Section 1: Load the data ----
data_path <- "raw_data"   # path to the data
files <- dir(data_path, pattern = "*.csv") # get file names
mydata <- files %>%
# read in all the files, appending the path before the filename
map(~ read_csv(file.path(data_path, .))) %>%
reduce(rbind)
#' filter the data to remove obvious outliers
mydata <- filter(mydata, lat < 20 & lat > -40 & long > 10)
head(mydata)
tail(mydata)
str(mydata)
levels(as.factor(mydata$study))
# Corinne Kendall's Tanzania Vulture Tracking Dataset
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# ck_tanz
# select ck_tanz data which is Corinne's data from everything
ck_tanz_data <- filter(mydata, study == "ck_tanz")
ck_tanz_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2<-ck_tanz_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
ck_tanz_data$dups <- ind2
ck_tanz_data <- filter(ck_tanz_data,dups=="FALSE")
ck_tanz_data
# set the time column
levels(factor(ck_tanz_data$id))
# can look at an individual level with
(filter(ck_tanz_data,id=="33021"))
# all of the data is in the format of day-month-year
ck_tanz_data$New_time<-parse_date_time(x=ck_tanz_data$time,c("%d/%m/%Y %H:%M"))
# keep only the new time data
ck_tanz_data <- select(ck_tanz_data, New_time,long,lat,id,species,study)
ck_tanz_data <- rename(ck_tanz_data, time = New_time)
ck_tanz_data
# check the minimum time and the maximum time
min_time <- ck_tanz_data %>% group_by(id) %>% slice(which.min(time))
data.frame(min_time)
max_time <- ck_tanz_data %>% group_by(id) %>% slice(which.max(time))
data.frame(max_time)
#' filter extreme data based on a speed threshold
#' based on vmax which is km/hr
#' time needs to be labelled DateTime for these functions to work
names(ck_tanz_data)[names(ck_tanz_data) == 'time'] <- 'DateTime'
SDLfilterData<-ddfilter.speed(data.frame(ck_tanz_data), vmax = 60, method = 1)
length(SDLfilterData$DateTime)
#' rename everything as before
ck_tanz_data <- SDLfilterData
names(ck_tanz_data)[names(ck_tanz_data) == 'DateTime'] <- 'time'
# try the amt package
trk <- mk_track(ck_tanz_data, .x=long, .y=lat, .t=time, id = id, species=species,
crs = CRS("+init=epsg:4326"))
#' we can transform the CRS of the data to an equal area projection
trk <-
transform_coords(
trk,
sp::CRS(
"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
)
)
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class <- class(trk)
# nest by id
nesttrk <- trk %>% nest(-id)
nesttrk
#' We can add a columns to each nested column of data using purrr::map
trk <- trk %>% nest(-id) %>%
mutate(
dir_abs = map(data, direction_abs, full_circle = TRUE, zero = "N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_ = map(data, nsd)
) %>% unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk <- trk %>%
mutate(
week = week(t_),
month = month(t_, label = TRUE),
year = year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk) <- trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
#' look at net-squared displacement
ggplot(trk, aes(x = t_, y = nsd_)) + geom_point() +
facet_wrap( ~ id, scales = "free")
5e+12
ck_tanz_data
head(trk)
head(ck_tanz_data)
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk <- trk %>%
mutate(
week = week(t_),
month = month(t_, label = TRUE),
year = year(t_),
hour = hour(t_)
)
#' Now, we need to again tell R that this is a track (rather
#' than just a data frame)
class(trk)
class(trk) <- trk.class
#' Lets take a look at what we created
trk <- trk %>% group_by(id)
trk
#' some data points look a little off
#' we can identify them to investiage further and remove them
#' if needs be
filter(trk, id == "163115" & nsd_ < 1e+11)
trk <- trk  %>%
filter(!((id == "163115" & nsd_ > 1e+11)))
#' plot it again
ggplot(trk, aes(x = t_, y = nsd_)) + geom_point() +
facet_wrap( ~ id, scales = "free")
#' ## Explore movement characteristics by (day/night, hour, month)
#'
#' ### step length distribution by day/night
#'
#+fig.height=12, fig.width=12, warning=FALSE, message=FALSE
ggplot(trk, aes(x = tod_, y = log(sl))) +
geom_boxplot()+geom_smooth()+facet_wrap(~id)
summary(trk$sl)
9559.6 / 1000
#' ---
#' title: "TestVignette"
#' author: "John Fieberg"
#' date: ""
#' ---
#'
#' ## Purpose
#'
#' - test whether you have everything set up for the workshop
#' - retrieve and explore animal movement data from Movebank
#' - illustrate how to work with functions in the animal movement tools package (amt)
#' - write out available points for further annotating in EnvDATA
#'
#'
#' #### Preamble
#'
#' Load libraries
#+warning=FALSE, message=FALSE
library(knitr)
library(lubridate)
library(maptools)
library(raster)
library(move)
library(amt)
library(ggmap)
library(tibble)
library(leaflet)
library(dplyr)
options(width=165,digits.secs = 3)
opts_chunk$set(fig.width=12,fig.height=4.5, error=TRUE,cache = F)
#' Record time for running all code
ptm<-proc.time()
#' Set the seed for the random number generator, so it will be possible
#' to reproduce the random points
set.seed(10299)
#' Create a login object for a user account at movebank.org
loginStored <- movebankLogin(username="MovebankWorkshop", password="genericuserforthisexercise")
getMovebankStudy(study="Martes pennanti LaPoint New York", login=loginStored) # see study-level info
#' Load data from a study in Movebank and create a MoveStack object. For more details and options see https://cran.r-project.org/web/packages/move/index.html.
fisher.move <- getMovebankData(study="Martes pennanti LaPoint New York", login=loginStored)
head(fisher.move)
#' Create a data frame from the MoveStack object
fisher.dat <- as(fisher.move, "data.frame")
#' Delete observations where missing lat or long or a timestamp.  There are no missing
#' observations in this data set, but it is still good practice to check.
ind<-complete.cases(fisher.dat[,c("location_lat", "location_long", "timestamp")])
fisher.dat<-fisher.dat[ind==TRUE,]
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier). There are no duplicate
#' observations in this data set, but it is still good practice to check.
ind2<-fisher.dat %>% select(timestamp, location_long, location_lat, local_identifier) %>%
duplicated
sum(ind2) # no duplicates
fisher.dat<-fisher.dat[ind2!=TRUE,]
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier). There are no duplicate
#' observations in this data set, but it is still good practice to check.
ind2<-fisher.dat %>% dplyr::select(timestamp, location_long, location_lat, local_identifier) %>%
duplicated
sum(ind2) # no duplicates
fisher.dat<-fisher.dat[ind2!=TRUE,]
33169 - 34634
#' Create a data frame from the MoveStack object
fisher.dat <- as(fisher.move, "data.frame")
fisher.dat
#' Delete observations where missing lat or long or a timestamp.  There are no missing
#' observations in this data set, but it is still good practice to check.
ind<-complete.cases(fisher.dat[,c("location_lat", "location_long", "timestamp")])
fisher.dat<-fisher.dat[ind==TRUE,]
fisher.dat
#' Make timestamp a date/time variable
fisher.dat$timestamp<-as.POSIXct(fisher.dat$timestamp, format="%Y-%m-%d %H:%M:%OS", tz="UTC")
#' Look at functions in the move package.
plot(fisher.move)
fisherF2<-fisher.dat %>% filter(local_identifier=="F2")
#' We can also use lat, long, which will allow us to determine
#' time of day
trk <- mk_track(fisher.dat, .x=location_long, .y=location_lat, .t=timestamp, id = local_identifier,
crs = CRS("+init=epsg:4326"))
# Now it is easy to calculate day/night with either movement track
trk <- trk %>% time_of_day()
#' Now, we can transform back to geographic coordinates
trk <- transform_coords(trk, CRS("+init=epsg:32618"))
#' Save the class here (and apply it later after adding columns to the
#' object)
trk.class<-class(trk)
#' individual (to avoid calculating a distance between say the last observation
#' of the first individual and the first observation of the second individual).
#'
#'
#' To do this, we could loop through individuals, calculate these
#' characteristics for each individual, then rbind the data
#' back together.  Or, use nested data frames and the map function
#' in the purrr library to do this with very little code.
#'
#' To see how nesting works, we can create a nested object by individual
nesttrk<-trk%>%nest(-id)
nesttrk
#' Each row contains data from an individual.  For example, we can access data
#' from the first individual using:
nesttrk$data[[1]]
#' We could calculate movement characteristics by individual using:
temp<-direction_rel(nesttrk$data[[1]])
head(temp)
#' or:
temp<-trk %>% filter(id=="M1") %>% direction_rel
head(temp)
#' Or, we can add a columns to each nested column of data using purrr::map
trk<-trk %>% nest(-id) %>%
mutate(dir_abs = map(data, direction_abs,full_circle=TRUE, zero="N"),
dir_rel = map(data, direction_rel),
sl = map(data, step_lengths),
nsd_=map(data, nsd))%>%unnest()
#' Now, calculate month, year, hour, week of each observation and append these to the dataset
#' Unlike the movement charactersitics, these calculations can be done all at once,
#' since they do not utilize successive observations (like step lengths and turn angles do).
trk<-trk%>%
mutate(
week=week(t_),
month = month(t_, label=TRUE),
year=year(t_),
hour = hour(t_)
)
trk
library(lubridate)
library(SDLfilter)
library(amt)
library(sp)
# select ck_tanz data which is Corinne's data from everything
ck_tanz_data <- filter(mydata, study == "ck_tanz")
ck_tanz_data
#' Check for duplicated observations (ones with same lat, long, timestamp,
#'  and individual identifier).
ind2 <- ck_tanz_data %>% select(long, lat, id) %>%
duplicated
sum(ind2)
# remove them
ck_tanz_data$dups <- ind2
ck_tanz_data <- filter(ck_tanz_data, dups == "FALSE")
ck_tanz_data
# set the time column
levels(factor(ck_tanz_data$id))
# can look at an individual level with
(filter(ck_tanz_data, id == "33021"))
